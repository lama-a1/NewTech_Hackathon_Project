{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPeksHOnVOEQhSqCR+nACa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lama-a1/NewTech_Hackathon_Project/blob/main/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "xtpvgLCPLB9a",
        "outputId": "53466dde-03c7-4c65-f33a-b0e9becfd1e5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2415966135.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# =========================\n",
        "# Optional XAI (Captum)\n",
        "# =========================\n",
        "try:\n",
        "    from captum.attr import IntegratedGradients\n",
        "    CAPTUM_OK = True\n",
        "except Exception:\n",
        "    CAPTUM_OK = False\n",
        "\n",
        "st.set_page_config(page_title=\"Sepsis Time-Machine Dashboard\", layout=\"wide\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model artifact path (in repo)\n",
        "# =========================\n",
        "CKPT_PATH = \"sepsis_gru_multistep_artifact.pt\"\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    st.error(\"âŒ Model artifact (.pt) not found in repository. Upload it to the repo root.\")\n",
        "    st.stop()\n",
        "\n",
        "# =========================\n",
        "# Model Definition (must match training)\n",
        "# =========================\n",
        "class GRUMultiTaskMultiStep(nn.Module):\n",
        "    def __init__(self, n_features, hidden, horizon, n_targets):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(n_features, hidden, batch_first=True)\n",
        "        self.shared = nn.Sequential(nn.LayerNorm(hidden), nn.Dropout(0.15))\n",
        "        self.forecast_head = nn.Linear(hidden, horizon * n_targets)\n",
        "        self.risk_head = nn.Linear(hidden, 1)\n",
        "        self.horizon = horizon\n",
        "        self.n_targets = n_targets\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        last = out[:, -1, :]\n",
        "        z = self.shared(last)\n",
        "        forecast = self.forecast_head(z).view(-1, self.horizon, self.n_targets)\n",
        "        risk_logit = self.risk_head(z)\n",
        "        return forecast, risk_logit\n",
        "\n",
        "class RiskOnlyWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "    def forward(self, x):\n",
        "        _, r = self.model(x)\n",
        "        return r\n",
        "\n",
        "# =========================\n",
        "# Load model artifact\n",
        "# =========================\n",
        "artifact = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "\n",
        "FEATURES = artifact[\"FEATURES\"]\n",
        "VITALS = artifact[\"VITALS\"]\n",
        "SEQ_LEN = int(artifact[\"SEQ_LEN\"])\n",
        "HORIZON = int(artifact[\"HORIZON\"])\n",
        "RISK_HORIZON = int(artifact[\"RISK_HORIZON\"])\n",
        "\n",
        "feat_mean = artifact[\"feat_mean\"]\n",
        "feat_std  = artifact[\"feat_std\"]\n",
        "tgt_mean  = artifact[\"tgt_mean\"]\n",
        "tgt_std   = artifact[\"tgt_std\"]\n",
        "\n",
        "model = GRUMultiTaskMultiStep(\n",
        "    n_features=len(FEATURES),\n",
        "    hidden=128,\n",
        "    horizon=HORIZON,\n",
        "    n_targets=len(VITALS)\n",
        ").to(DEVICE)\n",
        "\n",
        "model.load_state_dict(artifact[\"model_state\"])\n",
        "model.eval()\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def standardize(X):\n",
        "    X = (X - feat_mean) / feat_std\n",
        "    return np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "def destandardize(Y):\n",
        "    return Y * tgt_std.reshape(1,-1) + tgt_mean.reshape(1,-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(x_std):\n",
        "    x = torch.tensor(x_std).unsqueeze(0).to(DEVICE)\n",
        "    f, r = model(x)\n",
        "    return destandardize(f.squeeze(0).cpu().numpy()), torch.sigmoid(r).item()\n",
        "\n",
        "def plot_vital(hours_past, values_past, hours_future, values_future, vital, baseline=None):\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    ax.plot(hours_past, values_past, marker=\"o\", label=\"Observed (past)\")\n",
        "    ax.plot(hours_future, values_future, marker=\"X\", label=\"Forecast (next 6h)\")\n",
        "    ax.plot([hours_past[-1], hours_future[0]], [values_past[-1], values_future[0]], \"--\")\n",
        "    if baseline is not None:\n",
        "        ax.axhline(baseline, linestyle=\":\", linewidth=2, label=\"Patient baseline\")\n",
        "    ax.set_title(vital)\n",
        "    ax.set_xlabel(\"Hour\")\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "    return fig\n",
        "\n",
        "# =========================\n",
        "# UI: Upload CSV (instead of keeping it in repo)\n",
        "# =========================\n",
        "st.title(\"ðŸ©º Sepsis Time-Machine Dashboard (GRU + XAI)\")\n",
        "st.caption(\"Upload your PreprocessedDataset.csv (large files should NOT be stored in GitHub).\")\n",
        "\n",
        "uploaded_csv = st.sidebar.file_uploader(\"Upload PreprocessedDataset.csv\", type=[\"csv\"])\n",
        "if uploaded_csv is None:\n",
        "    st.info(\"â¬…ï¸ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù PreprocessedDataset.csv Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø«Ù… Ø³ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯.\")\n",
        "    st.stop()\n",
        "\n",
        "df = pd.read_csv(uploaded_csv)\n",
        "df.columns = df.columns.str.strip()\n",
        "df[\"Hour\"] = pd.to_numeric(df[\"Hour\"], errors=\"coerce\")\n",
        "df = df.sort_values([\"PatientID_tmp\", \"Hour\"]).reset_index(drop=True)\n",
        "\n",
        "# Check required columns\n",
        "missing = [c for c in ([\"PatientID_tmp\",\"Hour\",\"SepsisLabel\"] + FEATURES + VITALS) if c not in df.columns]\n",
        "if missing:\n",
        "    st.error(f\"Missing columns in uploaded CSV: {missing}\")\n",
        "    st.stop()\n",
        "\n",
        "# =========================\n",
        "# Sidebar selections\n",
        "# =========================\n",
        "st.sidebar.title(\"Patient Selection\")\n",
        "pid = st.sidebar.selectbox(\"PatientID\", df[\"PatientID_tmp\"].unique())\n",
        "g = df[df[\"PatientID_tmp\"] == pid].sort_values(\"Hour\").reset_index(drop=True)\n",
        "\n",
        "# Valid indices: need history + future\n",
        "valid_idx = []\n",
        "for i in range(len(g)):\n",
        "    if i >= SEQ_LEN-1 and i <= len(g) - HORIZON - 1:\n",
        "        valid_idx.append(i)\n",
        "\n",
        "if not valid_idx:\n",
        "    st.warning(\"This patient does not have enough history/future for prediction. Choose another patient.\")\n",
        "    st.stop()\n",
        "\n",
        "idx = st.sidebar.selectbox(\n",
        "    \"Current time (index)\",\n",
        "    valid_idx,\n",
        "    format_func=lambda i: f\"Hour {int(g.loc[i,'Hour'])}\"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Prepare model input\n",
        "# =========================\n",
        "X = standardize(g.loc[idx-SEQ_LEN+1:idx, FEATURES].values.astype(np.float32))\n",
        "forecast, risk = predict(X)\n",
        "\n",
        "hours_past = g.loc[idx-SEQ_LEN+1:idx, \"Hour\"].values\n",
        "current_hour = float(hours_past[-1])\n",
        "hours_future = np.arange(current_hour + 1, current_hour + 1 + HORIZON)\n",
        "\n",
        "# Baseline values if exist\n",
        "baseline_vals = None\n",
        "base_cols = [f\"base_mean_{v}\" for v in VITALS]\n",
        "if all(c in g.columns for c in base_cols):\n",
        "    baseline_vals = [float(g.loc[idx, c]) for c in base_cols]\n",
        "\n",
        "# =========================\n",
        "# Main metrics\n",
        "# =========================\n",
        "c1, c2, c3 = st.columns(3)\n",
        "c1.metric(\"PatientID\", str(pid))\n",
        "c2.metric(\"Current Hour\", str(int(current_hour)))\n",
        "c3.metric(f\"Sepsis Risk (next {RISK_HORIZON}h)\", f\"{risk*100:.1f}%\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# =========================\n",
        "# Plots\n",
        "# =========================\n",
        "st.subheader(\"â±ï¸ Observed (last 12h) + Forecast (next 6h)\")\n",
        "\n",
        "row1 = st.columns(3)\n",
        "row2 = st.columns(3)\n",
        "\n",
        "for j, vital in enumerate(VITALS):\n",
        "    fig = plot_vital(\n",
        "        hours_past,\n",
        "        g.loc[idx-SEQ_LEN+1:idx, vital].values,\n",
        "        hours_future,\n",
        "        forecast[:, j],\n",
        "        vital,\n",
        "        baseline_vals[j] if baseline_vals else None\n",
        "    )\n",
        "    if j < 3:\n",
        "        row1[j].pyplot(fig)\n",
        "    else:\n",
        "        row2[j-3].pyplot(fig)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# =========================\n",
        "# XAI (Integrated Gradients)\n",
        "# =========================\n",
        "st.subheader(\"ðŸ§  Explainable AI (XAI) â€“ Why is risk high?\")\n",
        "\n",
        "if not CAPTUM_OK:\n",
        "    st.warning(\"Captum not installed in deployment environment. Add 'captum' to requirements.txt.\")\n",
        "else:\n",
        "    with st.spinner(\"Computing Integrated Gradients...\"):\n",
        "        ig = IntegratedGradients(RiskOnlyWrapper(model).to(DEVICE))\n",
        "        x_t = torch.tensor(X).unsqueeze(0).to(DEVICE)\n",
        "        baseline = torch.zeros_like(x_t)\n",
        "        attr = ig.attribute(x_t, baselines=baseline, target=0, n_steps=64)\n",
        "\n",
        "    A = np.abs(attr.squeeze(0).detach().cpu().numpy())  # [T,F]\n",
        "    feat_imp = A.mean(axis=0)\n",
        "    top_k = 15\n",
        "    top_idx = np.argsort(-feat_imp)[:top_k]\n",
        "    top_feats = [FEATURES[i] for i in top_idx]\n",
        "\n",
        "    def doctor_text(f):\n",
        "        if f.startswith(\"d_\"):\n",
        "            return f\"Trend change in {f[2:]}\"\n",
        "        if f.endswith(\"_dev\"):\n",
        "            return f\"Deviation from baseline: {f[:-4]}\"\n",
        "        if f.endswith(\"_z\"):\n",
        "            return f\"Abnormality vs baseline: {f[:-2]}\"\n",
        "        return f\n",
        "\n",
        "    st.markdown(\"### âœ… Top-3 Clinical Reasons\")\n",
        "    for f in top_feats[:3]:\n",
        "        st.write(\"â€¢\", doctor_text(f))\n",
        "\n",
        "    st.markdown(\"### ðŸ” XAI Heatmap (Top-15 Features Ã— Past 12h)\")\n",
        "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
        "    im = ax.imshow(A[:, top_idx], aspect=\"auto\")\n",
        "    fig.colorbar(im, ax=ax, label=\"Attribution magnitude\")\n",
        "\n",
        "    ax.set_yticks(range(len(hours_past)))\n",
        "    ax.set_yticklabels(hours_past.astype(int))\n",
        "    ax.set_xticks(range(len(top_feats)))\n",
        "    ax.set_xticklabels(top_feats, rotation=60, ha=\"right\")\n",
        "\n",
        "    ax.set_xlabel(\"Top features\")\n",
        "    ax.set_ylabel(\"Past window hours\")\n",
        "    ax.set_title(f\"Integrated Gradients | Risk={risk*100:.1f}%\")\n",
        "    fig.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "st.caption(\"For clinicians: Risk% + Forecast + Top-3 reasons. Heatmap is for deeper inspection.\")\n"
      ]
    }
  ]
}